<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Trying to Predict NHL Game Outcomes with ML and Why It&#39;s Difficult | Colton</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Here I collect data from 17 NHL seasons beginning with the 2005-2006 season and ending with the 2021-2022 season. I extract the data directly from nhl.com using web scraping techniques (although there are a ton of better sites to get game data from). I clean the data and extract features from each team&rsquo;s individual performance. I calculate a rolling average/summary of multiple statistics for a few different timeframes and compare those to their opponent&rsquo;s same stats for each game.">
    <meta name="generator" content="Hugo 0.93.3" />
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="https://www.cbarger.com/ananke/css/main.min.css" >



    
    
    
      
<link rel="shortcut icon" href="https://www.cbarger.com/images/first-difference.png" type="image/x-icon" />


    

    
    
    <meta property="og:title" content="Trying to Predict NHL Game Outcomes with ML and Why It&#39;s Difficult" />
<meta property="og:description" content="Here I collect data from 17 NHL seasons beginning with the 2005-2006 season and ending with the 2021-2022 season. I extract the data directly from nhl.com using web scraping techniques (although there are a ton of better sites to get game data from). I clean the data and extract features from each team&rsquo;s individual performance. I calculate a rolling average/summary of multiple statistics for a few different timeframes and compare those to their opponent&rsquo;s same stats for each game." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.cbarger.com/projects/nhl-predictions/" /><meta property="article:section" content="projects" />
<meta property="article:published_time" content="2022-05-16T10:58:08-04:00" />
<meta property="article:modified_time" content="2022-05-16T10:58:08-04:00" /><meta property="og:site_name" content="Colton" />

<meta itemprop="name" content="Trying to Predict NHL Game Outcomes with ML and Why It&#39;s Difficult">
<meta itemprop="description" content="Here I collect data from 17 NHL seasons beginning with the 2005-2006 season and ending with the 2021-2022 season. I extract the data directly from nhl.com using web scraping techniques (although there are a ton of better sites to get game data from). I clean the data and extract features from each team&rsquo;s individual performance. I calculate a rolling average/summary of multiple statistics for a few different timeframes and compare those to their opponent&rsquo;s same stats for each game."><meta itemprop="datePublished" content="2022-05-16T10:58:08-04:00" />
<meta itemprop="dateModified" content="2022-05-16T10:58:08-04:00" />
<meta itemprop="wordCount" content="1440">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Trying to Predict NHL Game Outcomes with ML and Why It&#39;s Difficult"/>
<meta name="twitter:description" content="Here I collect data from 17 NHL seasons beginning with the 2005-2006 season and ending with the 2021-2022 season. I extract the data directly from nhl.com using web scraping techniques (although there are a ton of better sites to get game data from). I clean the data and extract features from each team&rsquo;s individual performance. I calculate a rolling average/summary of multiple statistics for a few different timeframes and compare those to their opponent&rsquo;s same stats for each game."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  
  <header class="cover bg-top" style="background-image: url('https://www.cbarger.com/images/nhl-logo.jpg');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://www.cbarger.com/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Colton
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://www.cbarger.com/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://www.cbarger.com/contact/" title="Contact Me page">
              Contact Me
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://www.cbarger.com/projects/" title="Projects page">
              Projects
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://www.cbarger.com/resume/" title="Resume page">
              Resume
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
    <a href="https://github.com/cbarger233" target="_blank" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel="noopener" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    <a href="https://www.linkedin.com/in/colton-barger-53158a14a/" target="_blank" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    <a href="https://medium.com/@cbarger233" target="_blank" class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Medium link" rel="noopener" aria-label="follow on Medium——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 170 170;" version="1.1" viewBox="0 0 170 170"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>
    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Trying to Predict NHL Game Outcomes with ML and Why It&#39;s Difficult</h1>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      
      <h1 class="f1 athelas mt3 mb1">Trying to Predict NHL Game Outcomes with ML and Why It&#39;s Difficult</h1>
      
      <p class="tracked">
          By <strong>
          
              Colton Barger
          
          </strong>
      </p>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2022-05-16T10:58:08-04:00">May 16, 2022</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>Here I collect data from 17 NHL seasons beginning with the 2005-2006 season and ending with the 2021-2022 season. I extract the data directly from <a href="https://www.nhl.com/stats/teams?aggregate=0&amp;reportType=game&amp;seasonFrom=20052006&amp;seasonTo=20202021&amp;dateFromSeason&amp;gameType=2&amp;filter=gamesPlayed,gte,1&amp;sort=a_gameDate&amp;page=0&amp;pageSize=100">nhl.com</a> using web scraping techniques (although there are a ton of better sites to get game data from). I clean the data and extract features from each team&rsquo;s individual performance. I calculate a rolling average/summary of multiple statistics for a few different timeframes and compare those to their opponent&rsquo;s same stats for each game.</p>
<p>As a baseline for my results, the home team won 8249 out of 16843 games during the time period my data is from. So if someone were to predict that the home team wins every game in the dataset, they would have an accuracy of 48.98%. My best model reaches an accuracy of 57.39%.</p>
<h2 id="previous-findings">Previous Findings</h2>
<p>In literature an accuracy of 61.54% was achieved by Gianni Pischedda from <a href="https://soccerlogic.com/" title="Hmmmm">soccerlogic.com</a> using ClusteR, a software developed for sports analysis. Those results can be read about <a href="https://www.researchgate.net/publication/284457066_Predicting_NHL_Match_Outcomes_with_ML_Models" title="Let's go there.">here</a>.</p>
<p>In a similar project GitHub user <a href="https://github.com/kn-kn" title="Link to Kevin's GitHub">kn-kn</a> was able to predict NHL game outcomes with anywhere from 53%-58% accuracy using decision trees and random forests and varying types of data attribute combinations.</p>
<p>In my analysis I use three different common ML models: logistic regression, random forest classification, and linear SVM. The best results thus far have been achieved using logistic regression with an accuracy of 57.3%.</p>
<h2 id="cleaning-data-and-making-features">Cleaning Data and Making Features</h2>
<p>Below is the DataFrame I was to be working with, after reading in the data to Python and an initial bit of data cleaning:</p>
<p><img src="https://www.cbarger.com/images/nhl_initial_data.PNG" alt="Initial DataFrame" title="The first five rows of the population dataset."></p>
<p>In the DataFrame, each row represents one game; however, as you can see by inspection, for each game there are two separate observations-one for each game. The only way to idientify who was the home team and who was the away team was by using the &lsquo;identifier&rsquo; column. If the identifier is &lsquo;vs&rsquo; then the team in the &rsquo;team&rsquo; column is the away team. If &lsquo;@&rsquo; then the team in the &rsquo;team&rsquo; column is the visiting team. In order to get the data in a way that I wanted I decided to split the DataFrame up by individual teams, which required that I make 33 separate DataFrames to calculate statistics on. Though inefficient, it was mostly a matter of copy-pasting code I had already written a bunch of times. In retrospect I might have written a function to avoid copy-pasting, but I had no idea the extent of what I was doing at the time.</p>
<p>For each team&rsquo;s DataFrame, I calculated various rolling statistics based on their performance in past games. These statistics would be the basis of what I train my machine learning algorithms on, as it would be ludicrous to predict the outcome of each game based off of that game&rsquo;s own statistics. My accuracy would have 100% accuracy in that case (ha). Dry humor aside, I calculated rolling statistics for the following statistics:</p>
<ul>
<li>points</li>
<li>goals</li>
<li>goals against</li>
<li>power play %</li>
<li>penalty kill %</li>
<li>shots on goal</li>
<li>shots against</li>
<li>faceoff win %</li>
<li>save percentage</li>
</ul>
<p>I calculate the average of all of these statistics over three different periods of time: a short window, medium window, and a long window of time. For the machine learning models I decided to play around with how long to make each window of time. Below are the different combinations I use for my models:</p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center"><strong>Short |</strong></th>
<th style="text-align:center"><strong>Medium |</strong></th>
<th style="text-align:center"><strong>Long</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Games</td>
<td style="text-align:center">10</td>
<td style="text-align:center">18</td>
<td style="text-align:center">30</td>
</tr>
<tr>
<td></td>
<td style="text-align:center">5</td>
<td style="text-align:center">10</td>
<td style="text-align:center">30</td>
</tr>
<tr>
<td></td>
<td style="text-align:center">15</td>
<td style="text-align:center">25</td>
<td style="text-align:center">40</td>
</tr>
<tr>
<td></td>
<td style="text-align:center">20</td>
<td style="text-align:center">40</td>
<td style="text-align:center">60</td>
</tr>
</tbody>
</table>
<p>After having done this for each team, each DataFrame was concatenated into one larger DataFrame.</p>
<p>But at this point you might be saying something along the lines of &ldquo;Colton, after doing this each game still has two columns that represent it. Why are you torturing us like this?!&rdquo;</p>
<p>Why yes, that is quite a good point.</p>
<p>To fix this, I split the DataFrame up <em>again</em> into home team and away team DataFrames. These two are them joined together based on the date an opponent. Finally, we have a DataFrame that</p>
<p><strong>a)</strong> has the data we want</p>
<p>and</p>
<p><strong>b)</strong> has one row representing each game</p>
<p>Before applying ML algorithms to the data, I wanted to make this project about trying to predict whether or not the home team was the winner in each game. To do this, I would need statistics comparing each rolling statistic of the home team to that of the away team. After standardizing the values and finding the differences between home and away team statistics I was set up to start throwing algorithms around.</p>
<h2 id="applying-different-ml-algorithms">Applying Different ML Algorithms</h2>
<p>Before applying different algorithms I initially set aside 30% of the data to be used as test data. The other 70% would be data used to train our models.</p>
<p>I was able to randomly select games to use as test data since my models were only to be based on time-series data that was already accounted for in each instance of our DataFrame.</p>
<h3 id="logistic-regression">Logistic Regression</h3>
<p>Logistic regression is a good starting algorithm when deciding between two things. In this case we are going to be predicting whether the home team wins (1) or loses (0).</p>
<p>The data was trained on the training data, and results based off of testing on the testing data is below.</p>
<p>A sample confusion matrix is shown below along with the accuracy, precision, and recall for the statistics that were calculated off of the varying window time lengths discussed above.</p>
<p><img src="https://www.cbarger.com/images/nhl_logistic_reg.png" alt="Initial DataFrame" title="Logistic Regression"></p>
<table>
<thead>
<tr>
<th>Time Windows |</th>
<th style="text-align:center"><strong>Precision</strong></th>
<th style="text-align:center"><strong>Accuracy</strong></th>
<th style="text-align:center"><strong>Recall</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>10, 18, 30</strong></td>
<td style="text-align:center">.5687</td>
<td style="text-align:center">.5694</td>
<td style="text-align:center">.5656</td>
</tr>
<tr>
<td><strong>5, 10, 30</strong></td>
<td style="text-align:center">.5634</td>
<td style="text-align:center">.5664</td>
<td style="text-align:center">.4702</td>
</tr>
<tr>
<td><strong>15, 25, 40</strong></td>
<td style="text-align:center">.5739</td>
<td style="text-align:center">.5677</td>
<td style="text-align:center">.5034</td>
</tr>
<tr>
<td><strong>20, 40, 60</strong></td>
<td style="text-align:center">.5699</td>
<td style="text-align:center">.5620</td>
<td style="text-align:center">.5112</td>
</tr>
</tbody>
</table>
<p>From looking at the confusion matrix, the logistic regression algorithm is more effective at predicting the outcome of home losses (~60% eyeball accuracy) than home victories (~53% accuracy). From the precision statistic, the time windows (15, 25, 40) works best for use on the rolling statistics in our dataset. However the time windows (10, 18, 30) have the best overall performance in terms of performance statistics.</p>
<p>What&rsquo;s great about the logistic regression model is that it&rsquo;s simple and easy to train, unlike more complex ML models. Let&rsquo;s take a look at a couple others.</p>
<h3 id="random-forest-classifier">Random Forest Classifier</h3>
<p>Shown below are the results of a random forest regressor trained on the training set. The max tree depth was set to 5 and the number of estimators was set to 200. For better results using random forests, I might consider using a grid search to look for optimal parameters in the future. But for now, I am not too worried. Future improvement will be more dependent on the quality of data in my opinion.</p>
<p><img src="https://www.cbarger.com/images/nhl_random_forest.png" alt="Initial DataFrame" title="Random Forest Classifier"></p>
<table>
<thead>
<tr>
<th>Time Windows |</th>
<th style="text-align:center"><strong>Precision</strong></th>
<th style="text-align:center"><strong>Accuracy</strong></th>
<th style="text-align:center"><strong>Recall</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>10, 18, 30</strong></td>
<td style="text-align:center">.5656</td>
<td style="text-align:center">.5631</td>
<td style="text-align:center">.5118</td>
</tr>
<tr>
<td><strong>5, 10, 30</strong></td>
<td style="text-align:center">.5594</td>
<td style="text-align:center">.5597</td>
<td style="text-align:center">.4794</td>
</tr>
<tr>
<td><strong>15, 25, 40</strong></td>
<td style="text-align:center">.5735</td>
<td style="text-align:center">.5657</td>
<td style="text-align:center">.5137</td>
</tr>
<tr>
<td><strong>20, 40, 60</strong></td>
<td style="text-align:center">.5668</td>
<td style="text-align:center">.5569</td>
<td style="text-align:center">.5208</td>
</tr>
</tbody>
</table>
<p>The confusion matrix for the random forest classifier has a different look than the one generated by logistic regression. Again, our model performs fairly well when predicting home losses. However we only have slightly above 50% accuracy in predicting home team victories. This continues the trend of models performing worse at predicting home wins than home losses.</p>
<p>Like the previous model our model has the highest precision when using the rolling statistics based on the (15, 25, 40) time windows.</p>
<h3 id="linear-svm">Linear SVM</h3>
<p>The final algorithm I decided to test out was a Linear SVM classifier. Shown below are the results from the test set.</p>
<p><img src="https://www.cbarger.com/images/nhl_linear_svm.png" alt="Initial DataFrame" title="Linear SVM Classifier"></p>
<table>
<thead>
<tr>
<th>Time Windows |</th>
<th style="text-align:center"><strong>Precision</strong></th>
<th style="text-align:center"><strong>Accuracy</strong></th>
<th style="text-align:center"><strong>Recall</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>10, 18, 30</strong></td>
<td style="text-align:center">.5656</td>
<td style="text-align:center">.5725</td>
<td style="text-align:center">.4527</td>
</tr>
<tr>
<td><strong>5, 10, 30</strong></td>
<td style="text-align:center">.5638</td>
<td style="text-align:center">.5766</td>
<td style="text-align:center">.4178</td>
</tr>
<tr>
<td><strong>15, 25, 40</strong></td>
<td style="text-align:center">.5708</td>
<td style="text-align:center">.5602</td>
<td style="text-align:center">.4671</td>
</tr>
<tr>
<td><strong>20, 40, 60</strong></td>
<td style="text-align:center">.5710</td>
<td style="text-align:center">.5684</td>
<td style="text-align:center">.4783</td>
</tr>
</tbody>
</table>
<p>Funny enough, we get the same exact plot for the confusion matrix as we did for the logistic regression. This model performs well on the true home losses and poorly on the true home wins. The highest precision was achieved using the (20, 40, 60) window time frames, just barely edging out the winner from the other two algorithms, the (15, 25, 40) rolling statistic time frame.</p>
<h2 id="conclusions">Conclusions</h2>
<p>I tested out some basic ML algorithms on nearly 17,000 NHL games played between 2005 and 2022. I achieved a peak accuracy of 57.39% using a logistic regression model with a rolling statistic timeframe of 15 games, 25 games, and 40 games to compare stats between two opposing teams.</p>
<p>The models tend to perform stronger when trying to predict true home losses rather than true wins by home teams. Further exploration into the data and the engineering of features will have to be done to figure out exactly why this is the case.</p>
<p>Everything I use here is available at the GitHub repository <a href="https://github.com/cbarger233/NHL-Scores-Predictions" title="General Kenobi">here</a>.</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-light-purple bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://www.cbarger.com" >
    &copy;  Colton 2022 
  </a>
    <div>
<div class="ananke-socials">
  
    <a href="https://github.com/cbarger233" target="_blank" class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel="noopener" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    <a href="https://www.linkedin.com/in/colton-barger-53158a14a/" target="_blank" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    <a href="https://medium.com/@cbarger233" target="_blank" class="medium ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="Medium link" rel="noopener" aria-label="follow on Medium——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 170 170;" version="1.1" viewBox="0 0 170 170"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M46.5340803,65.2157554 C46.6968378,63.6076572 46.0836,62.018231 44.8828198,60.93592 L32.6512605,46.2010582 L32.6512605,44 L70.6302521,44 L99.9859944,108.380952 L125.794585,44 L162,44 L162,46.2010582 L151.542017,56.2281011 C150.640424,56.9153477 150.193188,58.0448862 150.380019,59.1628454 L150.380019,132.837155 C150.193188,133.955114 150.640424,135.084652 151.542017,135.771899 L161.755369,145.798942 L161.755369,148 L110.38282,148 L110.38282,145.798942 L120.963119,135.527337 C122.002801,134.487948 122.002801,134.182246 122.002801,132.592593 L122.002801,73.0417402 L92.585901,147.755438 L88.6106443,147.755438 L54.3622782,73.0417402 L54.3622782,123.115814 C54.0767278,125.221069 54.7759199,127.3406 56.2581699,128.863022 L70.0186741,145.55438 L70.0186741,147.755438 L31,147.755438 L31,145.55438 L44.7605042,128.863022 C46.2319621,127.338076 46.8903838,125.204485 46.5340803,123.115814 L46.5340803,65.2157554 Z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div></div>
  </div>
</footer>

  </body>
</html>
